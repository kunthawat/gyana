# Generated by Django 3.2.7 on 2021-12-07 23:20

from datetime import timedelta
from uuid import uuid4

from django.db import migrations, models
from django_celery_results.models import TaskResult


class Kind(models.TextChoices):
    SHEET = "sheet", "Sheet"
    UPLOAD = "upload", "Upload"
    CONNECTOR = "connector", "Connector"


class State(models.TextChoices):
    UPDATE = "update", "Update"
    LOAD = "load", "Load"
    ERROR = "error", "Error"
    DONE = "done", "Done"


class RunState(models.TextChoices):
    PENDING = "pending", "Pending"
    RUNNING = "running", "Running"
    FAILED = "failed", "Failed"
    SUCCESS = "success", "Success"


class Source(models.TextChoices):
    INTEGRATION = "integration", "Integration"
    WORKFLOW = "workflow", "Workflow"


STATE_TO_RUN_STATE = {
    State.LOAD: RunState.RUNNING,
    State.ERROR: RunState.FAILED,
    State.DONE: RunState.SUCCESS,
}


def forwards(apps, schema_editor):
    Integration = apps.get_model("integrations", "Integration")
    JobRun = apps.get_model("runs", "JobRun")

    # to maintain backwards compatability for uploads and sheets, we need to generate
    # a mock run object and optionally a celery results task if it completed (success or error)
    # the original information is stored in the redis backend which is not persisted
    # for more than 24 hours

    for integration in Integration.objects.exclude(
        kind=Kind.CONNECTOR, state=State.UPDATE
    ):

        kind = integration.kind
        state = integration.state
        source_obj = getattr(integration, kind)
        # it really should exist, but just to be safe
        task_id = source_obj.sync_task_id or uuid4()
        sync_started = source_obj.sync_started or source_obj.created

        if task_id:
            JobRun.objects.create(
                integration=integration,
                source=Source.INTEGRATION,
                task_id=task_id,
                started_at=sync_started,
                # an estimate since we didn't track this information
                completed_at=sync_started + timedelta(seconds=5),
                state=STATE_TO_RUN_STATE[state],
            )


def backwards(apps, schema_editor):
    JobRun = apps.get_model("runs", "JobRun")

    JobRun.objects.all().delete()
    TaskResult.objects.all().delete()


class Migration(migrations.Migration):

    dependencies = [
        ("integrations", "0020_alter_integration_options"),
        ("uploads", "0010_alter_upload_options"),
        ("sheets", "0014_remove_sheet_next_daily_sync"),
        ("runs", "0001_initial"),
        ("django_celery_results", "0010_remove_duplicate_indices"),
    ]

    operations = [migrations.operations.RunPython(forwards, reverse_code=backwards)]
